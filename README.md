
# ResearchAssist â€“ AI-Powered Literature Review Assistant

## ğŸ“Œ Overview
**ResearchAssist** is an AI-powered academic assistant that automates literature review by:
- Searching across **multiple research sources** (Semantic Scholar, arXiv, Google Scholar)  
- Extracting and processing **full-text PDFs** of research papers  
- Building a **local vector database** for semantic search  
- Using **RAG (Retrieval-Augmented Generation)** with LLaMA 3 to answer research queries with **cited sources**  

This tool drastically reduces the time spent on finding, reading, and summarizing research papers, enabling faster **idea validation** and **knowledge discovery**.

---

## ğŸš€ Features
- ğŸ” **Multi-source Search** â€“ Fetch papers from **arXiv**, **Semantic Scholar**, and **Google Scholar**  
- ğŸ“„ **Full-Text Extraction** â€“ Automatically download and parse research PDFs  
- ğŸ“š **Semantic Search** â€“ Build a **FAISS**-powered local knowledge base  
- ğŸ¤– **AI-Powered Q&A** â€“ Retrieve relevant context and answer queries with citations using **Ollama + LLaMA**  
- âš¡ **Local & Free** â€“ Fully offline processing after data is downloaded  

---

## ğŸ›  Tech Stack
- **Python 3.10+**
- **LangChain** â€“ Vector store, RAG pipeline  
- **FAISS** â€“ Efficient semantic search  
- **SentenceTransformers** â€“ Paper embeddings (`all-MiniLM-L6-v2`)  
- **Ollama** â€“ Local LLaMA 3 inference  
- **Streamlit** â€“ Interactive UI  
- **PyMuPDF (fitz)** â€“ PDF parsing  
- **scholarly / arxiv API / Semantic Scholar API** â€“ Paper search  

---

## ğŸ“‚ Project Structure
\`\`\`
researchAssist/
â”‚â”€â”€ app.py                # Streamlit UI
â”‚â”€â”€ data_loader.py        # Fetch papers from multiple sources
â”‚â”€â”€ vectordb.py           # FAISS vector store builder
â”‚â”€â”€ rag_agent.py          # RAG pipeline with LLaMA
â”‚â”€â”€ llm.py                # LLaMA model loader
â”‚â”€â”€ config_loader.py      # Config management
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
\`\`\`

---

## âš™ï¸ Installation
\`\`\`bash
# Clone repository
git clone https://github.com/Prathamesh28/researchAssist.git
cd researchAssist

# Install dependencies
pip install -r requirements.txt

# Run Ollama server locally
ollama serve

# Start the Streamlit app
streamlit run app.py
\`\`\`

---

## ğŸ’¡ Usage
1. Enter a **research question** in the UI  
2. The system searches for relevant papers and downloads PDFs  
3. Papers are split into **chunks**, embedded, and indexed in FAISS  
4. AI retrieves relevant context and answers your question with **citations**  

---

## ğŸ“ˆ Impact
- Saves **hours of manual reading** by instantly summarizing relevant papers  
- Improves **research quality** with context-backed AI answers  
- Scales to **any research domain** without retraining  

---

## ğŸ“œ License
MIT License â€“ Free to use and modify.
