# ResearchAssist â€“ AI-Powered Literature Review Assistant

## ğŸ“Œ Overview
**ResearchAssist** is an AI-powered academic assistant that automates literature review by:
- Searching across **multiple research sources** (Semantic Scholar, arXiv, Google Scholar)  
- Extracting and processing **full-text PDFs** of research papers  
- Building a **local vector database** for semantic search  
- Using **RAG (Retrieval-Augmented Generation)** with LLaMA 3 to answer research queries with **cited sources**  

This tool drastically reduces the time spent on finding, reading, and summarizing research papers, enabling faster **idea validation** and **knowledge discovery**.

---
## Demo
[Click here for DEMO
]([https://prathamesh28.github.io/researchAssist/](https://prathamesh28.github.io/researchAssist/researchProjectDemo.mp4))
---

## ğŸš€ Features
- ğŸ” **Multi-source Search** â€“ Fetch papers from **arXiv**, **Semantic Scholar**, and **Google Scholar**  
- ğŸ“„ **Full-Text Extraction** â€“ Automatically download and parse research PDFs  
- ğŸ“š **Semantic Search** â€“ Build a **FAISS**-powered local knowledge base  
- ğŸ¤– **AI-Powered Q&A** â€“ Retrieve relevant context and answer queries with citations using **Ollama + LLaMA**  
- âš¡ **Local & Free** â€“ Fully offline processing after data is downloaded  

---

## ğŸ›  Tech Stack
- **Python 3.10+**
- **LangChain** â€“ Document processing & retrieval  
- **FAISS** â€“ Vector database for semantic search  
- **HuggingFace Embeddings** â€“ Sentence-transformers for text embeddings  
- **Ollama + LLaMA 3** â€“ Local LLM for Q&A  
- **PyMuPDF (fitz)** â€“ PDF parsing  
- **Scholarly, arxiv, Semantic Scholar API** â€“ Paper fetching  

---

## ğŸ“‚ Project Structure
```
researchAssist/
â”‚â”€â”€ app.py                 # Streamlit frontend for user interaction
â”‚â”€â”€ data_loader.py         # Multi-source research paper fetching
â”‚â”€â”€ vectordb.py            # FAISS vector database creation & indexing
â”‚â”€â”€ rag_agent.py           # RAG pipeline for AI-powered Q&A
â”‚â”€â”€ llm.py                  # Ollama LLaMA model integration
â”‚â”€â”€ config_loader.py       # Loads configuration settings
â”‚â”€â”€ requirements.txt       # Python dependencies
â”‚â”€â”€ README.md              # Project documentation
```

---

## âš™ï¸ Installation

1ï¸âƒ£ **Clone the Repository**
```bash
git clone https://github.com/Prathamesh28/researchAssist.git
cd researchAssist
```

2ï¸âƒ£ **Create Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate    # On Windows
```

3ï¸âƒ£ **Install Dependencies**
```bash
pip install -r requirements.txt
```

4ï¸âƒ£ **Install Ollama & LLaMA**
- Download Ollama from [https://ollama.ai](https://ollama.ai)  
- Pull LLaMA 3 model:
```bash
ollama pull llama3
```

---

## â–¶ï¸ Running the App
```bash
streamlit run app.py
```

---

## ğŸ’¡ Example Queries
- *"What are the loss functions used in CNN modelling for face detection?"*  
- *"Recent advancements in few-shot learning for NLP"*  
- *"How diffusion models are applied in image segmentation"*  

---

## ğŸ“œ License
MIT License Â© 2025 Prathamesh Wagh
